# Defenses Against Attacks by Content
List of papers on cognitive security for AI agents.

[![Maintenance](https://img.shields.io/badge/Maintained%3F-yes-green.svg)]([https://github.com/Cartus/Automated-Fact-Checking-Literature](https://github.com/MichSchli/AgentCogSec))
[![Last Commit](https://img.shields.io/github/last-commit/MichSchli/AgentCogSec)](https://github.com/MichSchli/AgentCogSec)
[![Contribution_welcome](https://img.shields.io/badge/Contributions-welcome-blue)](https://github.com/MichSchli/AgentCogSec/blob/main/contribute.md)

## Overview
This repo contains relevant resources from []. In this paper, we introduce attacks by content, a type of prompt injection where an attacker manipulates a RAG system or an AI agent by supplying biased, misleading, or false information. This differs from traditional prompt injection in that the surface form of the message is indistinguishable from legitimate content. The agent must therefore analyse the *content* of the message to identify the attack -- i.e., the agent must fact-check. In this repository, we curate a list of papers focusing on defending against such attacks. As the field evolves, we will provide timely updates in this repository.

- [Task Definition](#task-definition)
- [Claim Prioritisation](#claim-prioritisation)


## Task Definition
Figure below ...

## Claim Prioritisation

Bla

## Evidence Retrieval

Bla

## Source Criticism & Veracity Analysis

Bla
